{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27100de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-45dad4ed286c>:28: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  cv2.rectangle(img, (face[0],face[1]), (face[2], face[3]), (255,0,0), 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'unsqueeze'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(device=device)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "img = cv2.imread('../../data/train/NaMoonhee/nada1.jpeg')\n",
    "if img is None:\n",
    "    print(\"Img Err\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "s_face = 0\n",
    "faces, _ = mtcnn.detect(img)\n",
    "\n",
    "model.classify = True\n",
    "try:    \n",
    "    for face in faces:\n",
    "        face = np.trunc(face)\n",
    "        s_face = img[int(face[1]):int(face[3]), int(face[0]):int(face[2])]\n",
    "        \n",
    "        cv2.rectangle(img, (face[0],face[1]), (face[2], face[3]), (255,0,0), 3)\n",
    "        \n",
    "        i_c = mtcnn(s_face)\n",
    "        emb = model(i_c.unsqueeze(0))\n",
    "        print(emb)\n",
    "  \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "cv2.imshow(\"FACE\", img)\n",
    "cv2.imshow(\"img pos for emb\", s_face)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2757577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'JpegImageFile' object is not subscriptable\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected Ptr<cv::UMat> for argument 'mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dbb103e3428c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FACE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"img pos for emb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_face\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected Ptr<cv::UMat> for argument 'mat'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(device=device)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "img = cv2.imread('../../data/train/NaMoonhee/nada1.jpeg')\n",
    "if img is None:\n",
    "    print(\"Img Err\")\n",
    "    import sys\n",
    "    sys.exit()\n",
    "\n",
    "    \n",
    "img = Image.open('../../data/train/NaMoonhee/nada3.jpeg')\n",
    " \n",
    "img_cropped = mtcnn(img)\n",
    "tf = transforms.ToPILImage()\n",
    "img_t = tf(img_cropped)\n",
    "img_t.show()\n",
    "    \n",
    "    \n",
    "s_face = 0\n",
    "faces, _ = mtcnn.detect(img)\n",
    "\n",
    "model.classify = True\n",
    "try:    \n",
    "    for face in faces:\n",
    "        face = np.trunc(face)\n",
    "        s_face = img[int(face[1]):int(face[3]), int(face[0]):int(face[2])]\n",
    "        \n",
    "        cv2.rectangle(img, (face[0],face[1]), (face[2], face[3]), (255,0,0), 3)\n",
    "        \n",
    "        i_c = mtcnn(s_face)\n",
    "        emb = model(i_c.unsqueeze(0))\n",
    "        print(emb)\n",
    "  \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "cv2.imshow(\"FACE\", img)\n",
    "cv2.imshow(\"img pos for emb\", s_face)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96267105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
